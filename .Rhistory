data$values[2:(n-1)] < data$values[1:(n-2)] &
data$values[2:(n-1)] < data$values[3:n]
data <- data.frame(values = runif(10))
n <- nrow(data)
data$values[2:(n-1)] < data$values[1:(n-2)] &
data$values[2:(n-1)] < data$values[3:n]
data
c(F, data$values[2:(n-1)] < data$values[1:(n-2)] & data$values[2:(n-1)] < data$values[3:n], F)\
c(F, data$values[2:(n-1)] < data$values[1:(n-2)] & data$values[2:(n-1)] < data$values[3:n], F)
data %>% subset(c(F, data$values[2:(n-1)] < data$values[1:(n-2)] & data$values[2:(n-1)] < data$values[3:n], F))
install.packages('binom')
sample_size_prevalence <- function(s, N, prevalence.null, prevalence.alternative,
power = 0.8, sig.level = 0.05, alternative = 'greater',
sensitivity = 1, specificity = 1,
correlation = 0, form = 'logitnorm',
link = 'identity'){
thetaa <- prevalence.alternative
theta0 <- prevalence.null
if(!(alternative %in% c('less', 'greater'))){
stop('currently only supports one-sided tests. Valid options for alternative are less and greater')
}
if(alternative == 'less' & theta0 < thetaa){
stop('If alternative == "less", then prevalence.altnerative must be less than or equal to prevalence.null' )
}
if(alternative == 'greater' & theta0 > thetaa){
stop('If alternative == "greater", then prevalence.altnerative must be greater than or equal to prevalence.null' )
}
g <- switch(link,
logit = qlogis,
cloglog = cloglog,
log = log,
identity = function(x){x})
gdivinv <- switch(link,
logit = function(x){x * (1-x)},
cloglog = function(x){-log1p(-x) * (1-x)},
log = function(x){x},
identity = function(x){1})
unit_fia <- 1/(s*N) * gdivinv(thetaa)^2 /
solve(fi_pool_imperfect_cluster(s = s, N = N, p = thetaa,
sensitivity = sensitivity,
specificity = specificity,
correlation = correlation,
form = form))[1,1]
unit_fi0 <- 1/(s*N) * gdivinv(theta0)^2 /
solve(fi_pool_imperfect_cluster(s = s, N = N, p = theta0,
sensitivity = sensitivity,
specificity = specificity,
correlation = correlation,
form = form))[1,1]
# Note that the below is correct for either kind of one-sided test, but not for two sided tests
((qnorm(power)/sqrt(unit_fia) + qnorm(1 - sig.level)/sqrt(unit_fi0))/(g(theta0) - g(thetaa)))^2
}
sample_size_prevalence(10,10,0.01,0.02)
sample_size_prevalence(10,10,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,4,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,3,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,2,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,1,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,2,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,3,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,4,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,5,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,2,0.01,0.02, correlation = 0.1)
sample_size_prevalence(4,10,0.01,0.02, correlation = 0.1)
plot(function(x){n <- sample_size_prevalence(x,prevalence.null = 0.01, prevalence.alternative = 0.005, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less'); n + n/x}, from = 1, to = 40, n = 20, ylim = c(0, 7000))
Vectorize(optimise_s_prevalence_power)(0.01,seq(0.001,0.009,0.001),1,1.5, specificity = 0.99,correlation = 0, N = 1,alternative = 'less', interval = 0.05, link= 'logit')
plot(function(x){n <- sample_size_prevalence(x,4,prevalence.null = 0.01, prevalence.alternative = 0.005, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less'); n + n/x}, from = 1, to = 40, n = 20, ylim = c(0, 7000))
plot(function(x){n <- sample_size_prevalence(x,4,prevalence.null = 0.01, prevalence.alternative = 0.005, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less'); n + n/x}, from = 1, to = 40, n = 20, ylim = c(0, 7000))
sample_size_prevalence(x,4,prevalence.null = 0.01, prevalence.alternative = 0.005, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less')
sample_size_prevalence(1,4,prevalence.null = 0.01, prevalence.alternative = 0.005, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less')
plot(function(x){n <- sample_size_prevalence(x,4,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less'); n + n/x}, from = 1, to = 40, n = 20, ylim = c(0, 7000))
sample_size_prevalence(x,4,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less')
sample_size_prevalence(1,4,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less')
sample_size_prevalence(1.1,4,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less')
sample_size_prevalence(1.2,4,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less')
plot(function(x){n <- Vectorize(sample_size_prevalence)(x,4,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less'); n + n/x}, from = 1, to = 40, n = 20, ylim = c(0, 7000))
plot(function(x){n <- Vectorize(sample_size_prevalence)(x,2,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less'); n + n/x}, from = 1, to = 40, n = 20)
plot(function(x){n <- Vectorize(sample_size_prevalence)(x,2,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less'); n + n/x}, from = 1, to = 40, n = 40)
plot(function(x){n <- Vectorize(sample_size_prevalence)(x,2,prevalence.null = 0.01, prevalence.alternative = 0.005, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'less')}, from = 1, to = 40, n = 40)
plot(function(x){n <- Vectorize(sample_size_prevalence)(x,2,prevalence.null = 0.01, prevalence.alternative = 0.015, correlation = 0.1, link = 'logit', sensitivity = 1, specificity = 1, alternative = 'greater')}, from = 1, to = 40, n = 20, col = 'red', add = TRUE)
qnorm(0.8)
qnorm(0.99)
qnorm(0.999999)
qnorm(0.999999999999)
qnorm(0.05)
qnorm(0.95)
help(qnorm)
plot(function(x){binom::binom.power(x,alternative = 'less',n = 750,p = 0.01,method = 'asym')}, to = 0.01, n = 100000)
plot(function(x){binom::binom.power(x,alternative = 'less',n = 750,p = 0.01,method = 'logit')}, to = 0.01, n = 100000,add = TRUE)
plot(function(x){binom::binom.power(x,alternative = 'less',n = 750,p = 0.01,method = 'asym')}, to = 0.01, n = 100000)
plot(function(x){binom::binom.power(x,alternative = 'less',n = 750,p = 0.01,method = 'asym')}, to = 0.01, n = 100000)
plot(function(x){binom::binom.power(x,alternative = 'less',n = 750,p = 0.01,method = 'logit')}, to = 0.01, n = 100000,add = TRUE)
plot(function(x){Vectorize(power_fi)(750,10,2,prevalence.null = 0.01, prevalence.alternative = x, alternative = 'less' ,specificity = 1, correlation = 0.1)},  from = 0.01/100,to = 0.01, n = 100, add= TRUE)
power_fi <- function(n, s, N, prevalence.null, prevalence.alternative,
sig.level = 0.05, alternative = 'greater',
sensitivity = 1, specificity = 1,
correlation = 0, form = 'logitnorm',
link = 'identity'){
thetaa <- prevalence.alternative
theta0 <- prevalence.null
# The idea here was that the hypothesis test would be for mu rather than theta, with
# the idea that this would be equivalent to a test on theta, i.e. if mu0 =
# g(theta0)<g(thetaa) = mua then theta0 < thetaa. However, this is not true
# since differences in rho/correlations allows for theta0 > thetaa
# if(real.scale & form %in% c('logitnorm', 'cloglognorm')){ g <- function(x){
# #calculate mu from theta and rho .var <- correlation * x * (1-x)
# mu_sigma_linknorm(x,.var, link = switch(form, logitnorm = qlogis,
# cloglognorm = cloglog), invlink = switch(form, logitnorm = plogis,
# cloglognorm = cloglog_inv))[1] } gdivinv <- function(x){1}
# }else{
g <- switch(link,
logit = qlogis,
cloglog = cloglog,
log = log,
identity = function(x){x})
gdivinv <- switch(link,
logit = function(x){x * (1-x)},
cloglog = function(x){-log1p(-x) * (1-x)},
log = function(x){x},
identity = function(x){1})
# }
fia <- n/(s*N) * gdivinv(thetaa)^2 /
solve(fi_pool_imperfect_cluster(s = s, N = N, p = thetaa,
sensitivity = sensitivity,
specificity = specificity,
correlation = correlation,
form = form, real.scale = real.scale))[1,1]
#print(fia)
fi0 <- n/(s*N) * gdivinv(theta0)^2 /
solve(fi_pool_imperfect_cluster(s = s, N = N, p = theta0,  #should this be theta0 or thetaa?
sensitivity = sensitivity,
specificity = specificity,
correlation = correlation,
form = form, real.scale = real.scale))[1,1]
#print(fi0)
power <- switch(alternative,
less = pnorm(((g(theta0) - g(thetaa))  - qnorm(1-sig.level)/sqrt(fi0)) * sqrt(fia)),
greater = pnorm(((g(thetaa) - g(theta0))  - qnorm(1-sig.level)/sqrt(fi0)) * sqrt(fia)),
two.sided = pnorm(((g(theta0) - g(thetaa))  - qnorm(1-sig.level/2)/sqrt(fi0)) * sqrt(fia)) +
pnorm(((g(thetaa) - g(theta0))  - qnorm(1-sig.level/2)/sqrt(fi0)) * sqrt(fia)),
stop('invalid alternative. options are less, greater, and two.sided')
)
power
}
plot(function(x){Vectorize(power_fi)(750,10,2,prevalence.null = 0.01, prevalence.alternative = x, alternative = 'less' ,specificity = 1, correlation = 0.1)},  from = 0.01/100,to = 0.01, n = 100, add= TRUE)
power_fi <- function(n, s, N, prevalence.null, prevalence.alternative,
sig.level = 0.05, alternative = 'greater',
sensitivity = 1, specificity = 1,
correlation = 0, form = 'logitnorm',
link = 'identity'){
thetaa <- prevalence.alternative
theta0 <- prevalence.null
# The idea here was that the hypothesis test would be for mu rather than theta, with
# the idea that this would be equivalent to a test on theta, i.e. if mu0 =
# g(theta0)<g(thetaa) = mua then theta0 < thetaa. However, this is not true
# since differences in rho/correlations allows for theta0 > thetaa
# if(real.scale & form %in% c('logitnorm', 'cloglognorm')){ g <- function(x){
# #calculate mu from theta and rho .var <- correlation * x * (1-x)
# mu_sigma_linknorm(x,.var, link = switch(form, logitnorm = qlogis,
# cloglognorm = cloglog), invlink = switch(form, logitnorm = plogis,
# cloglognorm = cloglog_inv))[1] } gdivinv <- function(x){1}
# }else{
g <- switch(link,
logit = qlogis,
cloglog = cloglog,
log = log,
identity = function(x){x})
gdivinv <- switch(link,
logit = function(x){x * (1-x)},
cloglog = function(x){-log1p(-x) * (1-x)},
log = function(x){x},
identity = function(x){1})
# }
fia <- n/(s*N) * gdivinv(thetaa)^2 /
solve(fi_pool_imperfect_cluster(s = s, N = N, p = thetaa,
sensitivity = sensitivity,
specificity = specificity,
correlation = correlation,
form = form))[1,1]
#print(fia)
fi0 <- n/(s*N) * gdivinv(theta0)^2 /
solve(fi_pool_imperfect_cluster(s = s, N = N, p = theta0,  #should this be theta0 or thetaa?
sensitivity = sensitivity,
specificity = specificity,
correlation = correlation,
form = form))[1,1]
#print(fi0)
power <- switch(alternative,
less = pnorm(((g(theta0) - g(thetaa))  - qnorm(1-sig.level)/sqrt(fi0)) * sqrt(fia)),
greater = pnorm(((g(thetaa) - g(theta0))  - qnorm(1-sig.level)/sqrt(fi0)) * sqrt(fia)),
two.sided = pnorm(((g(theta0) - g(thetaa))  - qnorm(1-sig.level/2)/sqrt(fi0)) * sqrt(fia)) +
pnorm(((g(thetaa) - g(theta0))  - qnorm(1-sig.level/2)/sqrt(fi0)) * sqrt(fia)),
stop('invalid alternative. options are less, greater, and two.sided')
)
power
}
plot(function(x){Vectorize(power_fi)(750,10,2,prevalence.null = 0.01, prevalence.alternative = x, alternative = 'less' ,specificity = 1, correlation = 0.1)}, from = 0.01/100, to = 0.01, n = 100, ylim = c(0,1))
plot(function(x){Vectorize(power_fi)(750,10,2,prevalence.null = 0.01, prevalence.alternative = x, alternative = 'less' ,specificity = 1, correlation = 0.1)},  from = 0.01/100,to = 0.01, n = 100, add= TRUE)
plot(function(x){Vectorize(power_fi)(7500,10,2,prevalence.null = 0.01, prevalence.alternative = x, alternative = 'less' ,specificity = 1, correlation = 0.1)}, from = 0.01/100, to = 0.01, n = 100, ylim = c(0,1))
help("binom.power)
help("binom.power")
help(binom.power)
pwr
install.packages('pwr')
pwr::pwr.p.test()
help(pwr.p.test)
ES.h(0.5,0.4)
pwr::ES.h()
help(ES.h)
pwr::pwr.p.test(ES.h(0.01,0.015))
pwr.p.test(ES.h(0.01,0.015))
library(pwr)
pwr.p.test(ES.h(0.01,0.015))
pwr.p.test(h = ES.h(0.01,0.015), power = 0.8, sig.level = 0.05)
pwr.p.test(h = ES.h(0.01,0.015), power = 0.8, sig.level = 0.05, alternative = 'lower')
pwr.p.test(h = ES.h(0.01,0.015), power = 0.8, sig.level = 0.05, alternative = 'less')
pwr.p.test(h = ES.h(0.01,0.015), power = 0.8, sig.level = 0.05, alternative = 'greater')
pwr.p.test(h = ES.h(0.01,0.015), power = 0.8, sig.level = 0.05, alternative = 'less')
design_effect_cluster_fisher <- function(s,N,prevalence,sensitivity,specificity, correlation, form = 'beta'){
N * s * fi_pool_imperfect(1,prevalence,sensitivity,specificity) *
solve(fi_pool_imperfect_cluster(s,N,prevalence,sensitivity,specificity, correlation,form))[1,1]
}
theta <- 0.01
s <- 10
N <- 2
rho <- 0.1
design_effect_cluster_fisher(s,N,theta,1,1,rho, form = 'beta')
rm(theta)
sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less')
theta.alt  <- 0.015
sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less')
theta.null <- 0.01
design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'beta')
sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less')
theta.alt  <- 0.005
sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less')
sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less',correlation = 0.1)
pwr::pwr.p.test(h = pwr::ES.h(theta.null,theta.alt), power = 0.8, sig.level = 0.05, alternative = 'less')
pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = 0.8, sig.level = 0.05, alternative = 'less')
sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less',correlation = 0.1)
de <- design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'beta')
ss.indi.arcsin <- pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = 0.8, sig.level = 0.05, alternative = 'less')
ss.pool.asympt <- sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less',correlation = 0.1)
de <- design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'beta')
de
ss.indi.arcsin <- pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = 0.8, sig.level = 0.05, alternative = 'less')
ss.indi.arcsin
ss.pool.asympt <- sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less',correlation = 0.1)
ss.pool.asympt
ss.indi.arcsin$n
ss.indi.arcsin$n * de
de <- design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'beta')
de
ss.indi.arcsin <- pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = 0.8, sig.level = 0.05, alternative = 'less')
ss.indi.arcsin
ss.pool.asympt <- sample_size_prevalence(s,N,theta.null,theta.alt,0.8,sig.level = 0.05,alternative = 'less',correlation = 0.1)
ss.pool.asympt
ss.indi.arcsin$n * de
ss.pool.asympt
ss.indi.arcsin$n * de
de <- design_effect_cluster_fisher(s,N,theta.alt,1,rho, form = 'beta')
de
de <- design_effect_cluster_fisher(s,N,theta.alt,1,1,rho, form = 'beta')
de
ss.indi.arcsin$n * de
ss.pool.asympt
de <- design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'beta')
ss.indi.arcsin$n * de
%>%
library(tidyverse)
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = seq(0.001, 0.009,0.001),
s = 10, N = 2,
power = 0.8, sig.level = 0.05) %>%
rowwise() %>%
mutate(ss.indi.arcsin = pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = 'less'),
ss.pool.asympt = sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = 'less',correlation = rho),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin$n * de
)
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = seq(0.001, 0.009,0.001),
s = 10, N = 2,
power = 0.8, sig.level = 0.05) %>%
rowwise() %>%
mutate(ss.indi.arcsin = pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = 'less')$n,
ss.pool.asympt = sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = 'less',correlation = rho),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de
)
help(pivot_longer)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = n) %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line()
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line()
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
scale_y_log10()
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = seq(0.001, 0.009,0.001),
s = 4, N = 2,
power = 0.8, sig.level = 0.05) %>%
rowwise() %>%
mutate(ss.indi.arcsin = pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = 'less')$n,
ss.pool.asympt = sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = 'less',correlation = rho),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
scale_y_log10()
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = seq(0.001, 0.009,0.001),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>%
rowwise() %>%
mutate(ss.indi.arcsin = pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = 'less')$n,
ss.pool.asympt = sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = 'less',correlation = rho),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
scale_y_log10()
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.009,0.001),NA,seq(0.011, 0.02,0.001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>%
rowwise() %>%
mutate(ss.indi.arcsin = ifelse(is.na(theta.alt), NA, pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = ifelse(theta.alt < theta.null, 'less', 'greater'))$n),
ss.pool.asympt = ifelse(is.na(theta.alt), NA, sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = ifelse(theta.alt < theta.null, 'less', 'greater'),correlation = rho)),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
scale_y_log10()
NA * 3
sample.size.data
geom_line
help("geom_line")
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>%
rowwise() %>%
mutate(ss.indi.arcsin = ifelse(theta.alt == theta.null, NA, pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = ifelse(theta.alt < theta.null, 'less', 'greater'))$n),
ss.pool.asympt = ifelse(theta.alt == theta.null, NA, sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = ifelse(theta.alt < theta.null, 'less', 'greater'),correlation = rho)),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
scale_y_log10()
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>%
rowwise() %>%
mutate(ss.indi.arcsin = ifelse(theta.alt == theta.null, NA, pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = ifelse(theta.alt < theta.null, 'less', 'greater'))$n),
ss.pool.asympt = ifelse(theta.alt == theta.null, NA, sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = ifelse(theta.alt < theta.null, 'less', 'greater'),correlation = rho)),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>%
rowwise()
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>% with(theta.null - theta.alt)
expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>% with(theta.null - theta.alt)
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>% with(theta.null - theta.alt)
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>% #with(theta.null - theta.alt)
rowwise() %>%
mutate(ss.indi.arcsin = ifelse(abs(theta.alt - theta.null) < .Machine$double.eps, NA, pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = ifelse(theta.alt < theta.null, 'less', 'greater'))$n),
ss.pool.asympt = ifelse(abs(theta.alt - theta.null) < .Machine$double.eps, NA, sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = ifelse(theta.alt < theta.null, 'less', 'greater'),correlation = rho)),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
scale_y_log10()
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.0001)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>% #with(theta.null - theta.alt)
rowwise() %>%
mutate(ss.indi.arcsin = ifelse(abs(theta.alt - theta.null) < .Machine$double.eps, NA, pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = ifelse(theta.alt < theta.null, 'less', 'greater'))$n),
ss.pool.asympt = ifelse(abs(theta.alt - theta.null) < .Machine$double.eps, NA, sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = ifelse(theta.alt < theta.null, 'less', 'greater'),correlation = rho)),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
scale_y_log10()
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.0005)),
s = 4, N = 4,
power = 0.8, sig.level = 0.05) %>% #with(theta.null - theta.alt)
rowwise() %>%
mutate(ss.indi.arcsin = ifelse(abs(theta.alt - theta.null) < .Machine$double.eps, NA, pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = ifelse(theta.alt < theta.null, 'less', 'greater'))$n),
ss.pool.asympt = ifelse(abs(theta.alt - theta.null) < .Machine$double.eps, NA, sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = ifelse(theta.alt < theta.null, 'less', 'greater'),correlation = rho)),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
scale_y_log10()
sample.size.data <- expand.grid(theta.null = 0.01, rho = 0.1,
theta.alt  = c(seq(0.001, 0.02,0.0005)),
s = c(1,4,16,32), N = c(2,4,8,16),
power = 0.8, sig.level = 0.05) %>% #with(theta.null - theta.alt)
rowwise() %>%
mutate(ss.indi.arcsin = ifelse(abs(theta.alt - theta.null) < .Machine$double.eps, NA, pwr::pwr.p.test(h = pwr::ES.h(theta.alt,theta.null), power = power, sig.level = sig.level, alternative = ifelse(theta.alt < theta.null, 'less', 'greater'))$n),
ss.pool.asympt = ifelse(abs(theta.alt - theta.null) < .Machine$double.eps, NA, sample_size_prevalence(s,N,theta.null,theta.alt,power,sig.level = sig.level,alternative = ifelse(theta.alt < theta.null, 'less', 'greater'),correlation = rho)),
de = design_effect_cluster_fisher(s,N,theta.null,1,1,rho, form = 'logitnorm'),
ss.de = ss.indi.arcsin * de)
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
facet_grid(s,N)+
scale_y_log10()
facet_grid(vars(s),vars(N)+
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
facet_grid(s~N)+
scale_y_log10()
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
facet_grid(vars(s),vars(N))+
scale_y_log10()
sample.size.data %>%
pivot_longer(cols = starts_with('ss'), names_to = 'method',values_to = "n") %>%
ggplot(aes(x = theta.alt, y = n, color = method)) +
geom_line() +
facet_grid(vars(s),vars(N)) +
scale_y_log10()
pwr::pwr.p.test()
help(pwr.p.test)
pwr.p.test
quote
help(quote)
qnorm(pnorm(1))
qnorm(pnorm(seq(-1,1,0.01)))
asin
help(asin)
sin(asin(1))
sin(asin(0.1))
sin(asin(2))
sin(asin(0.3))
qnorm(0.05)
qnorm(1-0.05)
arcsin(theta.null)
asin(theta.null)
asin(theta.null) - asin(theta.alt)
2*(asin(theta.null) - asin(theta.alt))
2*(asin(theta.null) - asin(theta.alt)) * 1000
2*(asin(theta.null) - asin(theta.alt)) * 1000 - qnorm(0.05)
pnorm(2*(asin(theta.null) - asin(theta.alt)) * 1000 - qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * 1000 - qnorm(0.05)) - 1
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(1000) - qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(800) - qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(700) - qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(500) - qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(200) - qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(100) - qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(100) + qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(700) + qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(7000) + qnorm(0.05))
pnorm(2*(asin(theta.null) - asin(theta.alt)) * sqrt(70000) + qnorm(0.05))
pnorm(-2*(asin(theta.alt) - asin(theta.null)) * sqrt(700) - qnorm(0.05))
pnorm(-2*(asin(theta.alt) - asin(theta.null)) * sqrt(700) + qnorm(0.05))
pnorm(2*(asin(theta.alt) - asin(theta.null)) * sqrt(700) + qnorm(0.05))
pnorm(2*(asin(sqrt(theta.alt)) - asin(sqrt(theta.null))) * sqrt(700) + qnorm(0.05))
pnorm(-2*(asin(sqrt(theta.alt)) - asin(sqrt(theta.null))) * sqrt(700) + qnorm(0.05))
pnorm(-2*(asin(sqrt(theta.alt)) - asin(sqrt(theta.null))) * sqrt(800) + qnorm(0.05))
pnorm(-2*(asin(sqrt(theta.alt)) - asin(sqrt(theta.null))) * sqrt(200) + qnorm(0.05))
pnorm(-2*(asin(sqrt(theta.alt)) - asin(sqrt(theta.null))) * sqrt(2000) + qnorm(0.05))
pwr::pwr.p.test(pwr::ES.h(theta.alt,theta.null),n = 2000,alternative = 'less')
qnorm(power)
((qnorm(0.8) + qnorm(0.05))/(2*(asin(sqrt(theta.null)) - asin(sqrt(theta.alt)))))^2
((qnorm(0.8) - qnorm(0.05))/(2*(asin(sqrt(theta.null)) - asin(sqrt(theta.alt)))))^2
pwr::pwr.p.test(pwr::ES.h(theta.alt,theta.null),power = 0.8,alternative = 'less')
